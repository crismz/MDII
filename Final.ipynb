{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNNwz6vcPtu/HefSHmc8y+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crismz/MDII/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Respuestas a posibles preguntas de ML\n",
        "\n",
        "- **¿En qué tipo de problemas es adecuado utilizar aprendizaje automático?**\n",
        "\n",
        "En problemas donde es díficil definir reglas (como relaciones lógicas o funciones matemáticas) de forma manual y necesitamos automatizar este proceso de relacionar variables independientes (input) de variables dependientes (output).\n",
        "\n",
        "- **¿Cuál es la diferencia entre la función de costo o pérdida, y las métricas de rendimiento del modelo?**\n",
        "\n",
        "La función de costo o pérdida es la que intenta minimizar el optimizador que usemos, mientras que las métricas de rendimiento son para que un humano pueda evaluar el desempeño. Es decir las métrocas de rendimiento son para que nosotros sepamos si esta mejorando en hacer la tarea, y la función de pérdida para minimar el optimizador ya que es más facil de minimizar computacionalmente.\n",
        "\n",
        "- **¿Cómo se puede entrenar un modelo utilizando features o características no numéricas?**\n",
        "\n",
        "Para esto, deben codificarse estos features de forma tal que sean transformados en una o varias entradas numéricas. Un ejemplo es el one-hot encoding.\n",
        "\n",
        "- **Explique por qué se intenta minimizar la función de costo utilizando un método iterativo (numérico) y no un método analítico minimizando la derivada de la función?**\n",
        "\n",
        "Mnimizar de manera analítica es muy díficil para funciones más complejas. Al usar un método numérico mitigamos el costo y obtenemos resultados suficientemente buenos.\n",
        "\n",
        "- **¿Por qué el algoritmo SGD se llama “estocástico”?**\n",
        "\n",
        "Esto viene de que el gradiente que calculamos es solo una aproximación estocástica (al azar) del \"valor real\" del gradiente, dado que no es posible calcular la función de pérdida usando todos los datos presentes en el universo y solo usamos una porción de ellos.\n",
        "\n",
        "Nota: estocástico es ser caracterizado por una distribución de variable aleatoria. Es similar a aleatorio y muchas veces se usa de forma indistinta. Pero siendo finos, aleatoriedad es un fenómeno concreto y lo estocástico tiene más que ver con como se modela.\n",
        "\n",
        "- **¿Qué impacto tiene el learning rate en la optimización de la función?**\n",
        "\n",
        "El optimizador va a usar el learning rate para determinar cuánto hacer variar los pesos en cada iteración. Un learning rate demasiado grande puede causar divergencia u oscilamiento alrededor del mínimo global. Mientras que un learning rate demasiado pequeño puede hacer muy largo el tiempo necesario para que método llegue a converger (más tiempo de calculos).\n",
        "\n",
        "- **Si una red tiene muy buen rendimiento durante el entrenamiento, pero muy bajo rendimiento en un conjunto de datos de evaluación, ¿qué acciones tomaría para mejorar el modelo?**\n",
        "\n",
        "Esto es un ejemplo de overfitting. En este caso podríamos reducir la cantidad de features, la cantidad de neuronas / capas, regularizando o aplicar dropout.\n",
        "\n",
        "- **Si una red tiene muy bajo rendimiento durante el entrenamiento ¿qué acciones tomaría para mejorar el modelo?**\n",
        "\n",
        "Esto es un ejemplo de underfitting, se soluciona agregando más features o complejizando el modelo.\n",
        "\n",
        "- **¿Por qué inicializamos los pesos de un modelo en valores aleatorios? ¿Qué pasaría si los inicializamos todos en cero? ¿Y todos en uno?**\n",
        "\n",
        "Inicializamos en valores aleatorios para evitar problemas como el vanishing gradient y el exploting gradient, producto de inicializar los pesos en valores fijos particulares como 0 y 1.También si todos los pesos se inicializan con el mismo valor constante, cada neurona aprendera lo mismo con lo cuál serían todas redundantes.\n",
        "\n",
        "- **¿Por qué el dropout puede ser considerado una técnica de regularización?**\n",
        "\n",
        "La regularización se usa para mitigar el overfitting. Esto se da cuando el modelo tiene la capacidad de acercarse demasiado (a modo de memorización) a los datos de entrenamiento.\n",
        "\n",
        "En redes neuronales, el dropout consiste en \"apagar\" o \"quitar\" conexiones entre neuronas y así evitar que se aprendan relaciones que consistan en \"memorizar\" los datos de entrenamiento.\n",
        "\n",
        "- **¿Por qué está recomendada la estandarización de los valores de entrada de un modelo de machine learning?**\n",
        "\n",
        "El optimizador puede llegar a ser sensible a la variabilidad en la escala en la que puede variar cada feature, y por ende darle más peso a un feature que a otro. Pro eso, tener todas las entradas con desviación estándar 1 es útil.\n",
        "\n",
        "# Resumen\n",
        "\n",
        "- **Machine Learning**\n",
        "Un programa aprende a partir de la experiencia E con respecto a una tarea T y una medida de rendimiento P, si su desempeño en la tarea T, medido a través de P, mejora con la experiencia E.\n",
        "\n",
        "Un programa que generaliza patrones en datos de ejemplo utilizados durante un entrenamiento para ejemplos nunca antes vistos.\n",
        "\n",
        "- **Evaluación**\n",
        "\n",
        "Si se usa un solo conjunto de datos, el mismo se tiene que dividir en dos partes:\n",
        "\n",
        "- Entrenamiento: un 80% para minimar la función de pérdida\n",
        "\n",
        "- Evaluación: un 20% que no utilizaremos en el entrenamiento, y que nos serviran para medir el rendimiento del modelo en ejemplos que no ha visto previamente.\n",
        "\n",
        "- **Underfitting**\n",
        "\n",
        "No tiene suficiente información para predecir los valores\n",
        "\n",
        "- **Overfitting**\n",
        "\n",
        "Cuando el modelo se ajusta demasiado a los datos de entrenamiento y no generaliza bien a nuevos datos o conjuntos de prueba\n",
        "\n",
        "- **Regularización**\n",
        "\n",
        "Agregar una penalización adicional a la función de pérdida para limitar la complejidad del modelo y el sobreajuste. Por ejemplo L1, L2 y dropout.\n",
        "\n",
        "\n",
        "- **Hiperparametros**\n",
        "\n",
        "  - **Learning rate:** Determina la magnitud de los ajustes realizados en los parámetros del modelo  en cada iteración del algoritmo. Si es muy grande puede no converger, oscilar o diverger. Si es muy chico la convergencia va a ser muy lenta requiriendo mayor número de iteraciones.\n",
        "\n",
        "  - **Cantidad de capas:** Mientras mas capas, tendrá potencialmente la capacidad de representar porblemas donde las relaciones entre las causas latentes son más complicadas, como en el caso de las imagenes. Pero será más difícil de entrenar.\n",
        "\n",
        "  - **Cantidad de neuronas:** Mientras mas neuronas tenga, tendrá potencialmente la capacidad de representar problemas más complejos, como por ejemplo el lenguaje. Pero necesitaremos más datos para entrenarla.\n",
        "\n",
        "  - **Funciones de activación:** Introducen no linealidad en el modelo. Permite que la red neuronal aprenda y represente relaciones más complejas en los datos.\n",
        "\n",
        "  - **Optimizador**: La función que va a encontrar el valor de los parametros que minimiza la función de pérdida. Existen muchos tipos distintos, vimos el SGD (Descenso Estocástico por el Gradiente). El optimizador es independiente del tipo de modelo utilizado.\n",
        "\n",
        "  - **N° de epochs:** Determina cuántas veces iteraremos sobre el conjunto de datos.\n",
        "\n",
        "\n",
        "\n",
        "- **Estandarización del input**\n",
        "\n",
        "Es transformar los datos de entrada (features) de manera que tengan una media de cero y una desviación estándar de uno. Esta transformación se realiza para lograr una distribución de los datos más cercana a una distribución normal o gaussiana.\n",
        "\n",
        "- **Batching**\n",
        "\n",
        "Se elige un subconjuto de todo el dataset para trabajar y hacer el computo más rápido.\n"
      ],
      "metadata": {
        "id": "oWWP6g5AVhgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 1.Complejidad de Edmonds-Karp\n",
        "\n",
        "La complejidad es $O(nm^2)$\n",
        "\n",
        "## Estructura\n",
        "\n",
        "Supondremos que no existen arcos paralelos xy e yx. Es decir que si está el lado $\\overrightarrow{xy}$ entonces no está el lado $\\overrightarrow{yx}$.  \n",
        "Esta propiedad no es restrictiva, ya que para cualquier network N que presente arcos paralelos, podemos dar un N' tal que sea como N pero con vértices \"intermedios\" adicionales en medio de cada arco paralelo.\n",
        "\n",
        "Primero queremos ver que los flujos parciales $f_0, f_1, f_2, ...$ son finitos y daremos una cota para la cantidad.\n",
        "\n",
        "Como la búsqueda y construcción de cada flujo parcial se hace con BFS, cada incremento tiene complejidad $O(m)$ (máximo vas a tener que ver todos los lados hasta llegar a $t$).\n",
        "\n",
        "Si probamos que solo puede haber $O(nm)$ búsquedas, entonces habremos probado la complejidad de E-K: $O(nm) * O(m) = O(n*m^2)$.\n",
        "\n",
        "### Pasos de estructura\n",
        "\n",
        "\n",
        "*   Damos lemas y definiciones\n",
        "*   Acotamos la cantidad de veces que se puede volver crítico un lado ($O(n)$)\n",
        "*   Concluimos que todo lado puede volverse crítico $O(n)$ veces, y siempre se vuelve crítico un lado en un nuevo paso de E-K, la cantidad de paso es $O(n*m)$.\n",
        "*   La complejidad total es entonces $O(n*m^2)$\n",
        "\n",
        "## Definiciones / Lemas internos\n",
        "\n",
        "### Lema de las distancias\n",
        "\n",
        "Las distancias $d_k(x)$ y $b_k(x)$ son <= a $d_{k+1}(x)$ y $b_{k+1}(x)$ respectivamente\n",
        "\n",
        "### Lado crítico\n",
        "\n",
        "Un lado xy se vuelve crítico si se satura completamente o se vacía complemantente\n",
        "\n",
        "### Distancias\n",
        "\n",
        "$d_k(x)$ = longitud del menor $f_k\\text{-CA}$ de $s$ a $x$ = $d_{f_k}(s,x)$\n",
        "\n",
        "$b_k(x)$ = longitud del menor $f_k\\text{-CA}$ de $x$ a $t$ = $d_{f_k}(x,t)$\n",
        "\n",
        "## Prueba\n",
        "\n",
        "Acotemos cuantas veces puede un lado volverse crítico.\n",
        "\n",
        "Supongamos que en el paso k se satura $xy$ para obtener el flujo $f_{k+1}$, por lo tanto existe un camino de longitud mínima s...xy...t. Entonces\n",
        "\n",
        "$$ d_k(y) = d_k(x)+1 \\text{ (i)}$$\n",
        "\n",
        "Luego para que se vuelva a hacer crítico xy en un paso $r$ tiene que haber pasado por un paso intermedio $l$ tal que $r \\geq l > k$ en el que se vacíe al menos un poco. **Ya sea para que se vuelva a saturar, o bien que se vacíe por completo en esa misma instancia o luego. Tenemos entonces un camino s...$\\overleftarrow{xy}$...t y por lo tanto\n",
        "\n",
        "$$ d_l(x) = d_l(y) + 1  \\text{ (ii)}$$\n",
        "\n",
        "Ahora hacemos cuentas para ver cuanto tiene que aumentar la distancia a t entre cada evento de criticalidad sobre un lado xy:\n",
        "\n",
        "$$ d_l(t) = d_l(x) + b_l(x) $$\n",
        "$$d_l(t) = d_l(y) + 1 + b_l(x)  \\text{ por (ii)}$$\n",
        "$$d_l(t) \\geq d_k(y) + 1 + b_k(x) \\text{ por lema de distancias}$$\n",
        "$$d_l(t) \\geq d_k(x) + 1 + 1 + b_k(x) \\text{ por (i)}$$\n",
        "$$d_l(t) \\geq d_k(t) + 2$$\n",
        "\n",
        "Ahora veamos el caso en el que se vacía $xy$ para obtener el flujo $f_{k+1}$: Mismo planteo con $r \\geq l > k$ pero en este caso tenemos que en el paso k el camino $s...xy...t$ y por lo tanto\n",
        "\n",
        "$$d_k(x) = d_k(y) + 1 \\text{ (iii)}$$\n",
        "\n",
        "Luego en el paso $l$ tenemos que se debe saturar del todo o un poco el lado xy. Tenemos\n",
        "\n",
        "$$d_l(y) = d_l(x) +1 \\text{ (iv)}$$\n",
        "\n",
        "Hacemos la cuenta otra vez\n",
        "\n",
        "$$ d_l(t) = d_l(y) + b_l(y) $$\n",
        "$$d_l(t) = d_l(x) + 1 + b_l(y)  \\text{ por (iv)}$$\n",
        "$$d_l(t) \\geq d_k(x) + 1 + b_k(y) \\text{ por lema de distancias}$$\n",
        "$$d_l(t) \\geq d_k(y) + 1 + 1 + b_k(y) \\text{ por (iii)}$$\n",
        "$$d_l(t) \\geq d_k(t) + 2$$\n",
        "\n",
        "En ambos casos vemos que $d_r(t) \\geq d_l(t) => d_r(t) \\geq d_k(t)+2$\n",
        "\n",
        "Como la máxima distancia hasta t es n-1, tenemos que un lado puede hacerse crítico $\\frac{n-1}{2}$ veces: $O(n)$.\n",
        "\n",
        "Por lo tanto, la complejidad total, sabiendo que tenemos $m$ lados y se usa BFS para la búsqueda los flujos, es $O(flujos * BFS) = O(m*n*m) = O(n*m^2)$."
      ],
      "metadata": {
        "id": "Z4mjTdEHozWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------\n",
        "# 2.Propiedad de las distancias\n",
        "\n",
        "Probar que si dado dos vértices x,z y flujo f definimos a la distancia entre x y z relativa a f como la longitud del menor f-CA entre x y z, si es que existe tal camino, o infinito si no existe, o si 0 si x=z, denotándola por $d_f(x,z)$, y definimos $d_k(x) = d_{f_k}(s,x)$, donde $f_k$ es el k-ésimo flujo en una corrida de E-K, entonces $d_k(x) <= d_{k+1}(x)$.\n",
        "\n",
        "## Definiciones\n",
        "\n",
        "### fFF vecino\n",
        "\n",
        "Decimos que z es fFF vecino de x si desde x podemos envíar flujo a z o devolver flujo a z.\n",
        "\n",
        "## Estructura\n",
        "\n",
        "*   Asumimos $A = \\{y : d_{k+1}(y) < d_k(y)\\} \\ne \\emptyset$\n",
        "*   Tomamos un $x$ de $A$ tal que $d_{k+1}(x)$ sea mínimo ($d_{k+1}(x) <= d_{k+1}(y)$ para todo $y$ que pernetece a $A$)\n",
        "* Probamos que existen un z anterior a x desde el que antes no podías llegar a x pero ahora si. Vemos que dada esa situación, $z$ no pertenece a $A$, y por lo tanto $d_k(x) > d_k(z) + 1$.\n",
        "* Luego resta ver que para que esto haya ocurrido, antes tomamos un camino s...xz...t y por lo tanto $d_k(z) = d_k(x)+1$\n",
        "* Usando las dos conclusiones anteriores, llegamos a $0 > 2$\n",
        "\n",
        "## Prueba\n",
        "\n",
        "Suponemos $A = \\{y : d_{k+1}(y) < d_k(y)\\}$ distinto de vacío y veamos de llegar a un absurdo.\n",
        "\n",
        "Siendo $A \\ne \\emptyset$, tomamos un $x$ tal que $d_{k+1}(x) \\leq d_{k+1}(y)\n",
        " \\forall y \\in A$. Es decir tomamos un x tal que la $d_{k+1}(x)$ es mínimo.\n",
        "\n",
        "Por hipótesis tenemos que $d_{k+1}(x) < d_k(x) \\leq \\infty$ y por lo tanto existe un $f_{k+1}-CA$ de menor longitud hasta x.\n",
        "\n",
        "Observación: $s \\notin A$ ya que $d_{k+1}(s) = d_k(s) = 0$.\n",
        "\n",
        " Como $s \\notin A$ entonces existe un z directamente anterior a x tal que $d_{k+1}(x) = d_{k+1}(z) + 1$, pues x es fFF vecino de z. Entonces $d_{k+1}(z) < d_{k+1}(x)$ por lo tanto $z \\notin A$ porque x era el mínimo. Y luego $d_{k+1}(z) \\geq d_k(z)$.\n",
        "\n",
        " Entonces tenemos:\n",
        "  \n",
        "$$d_k(x) > d_{k+1}(x) \\text{ porque } x \\in A$$\n",
        "\n",
        "$$d_k(x) > d_{k+1}(z)+1  \\text{ porque x es fFF vecino de z}$$\n",
        "\n",
        "$$d_k(x) > d_k(z)+1$$\n",
        "\n",
        "Por lo tanto x no es fFF vecino de z en el paso k.\n",
        "\n",
        "Esto **solo puede pasar** si el camino que usamos para pasar de $f_k$ a $f_{k+1}$ incluye $\\overrightarrow{xz}$ o $\\overrightarrow{zx}$. Veamos cada caso:\n",
        "\n",
        "* $\\overrightarrow{xz}$. Tenemos que $f_k(\\overrightarrow{xz})$ = 0 y $f_{k+1}(\\overrightarrow{xz}) > 0$ por lo que vimos de la vecindad de z a x en cada paso. Por lo tanto de k a k+1 ENVIAMOS flujo de x a z.\n",
        "* $\\overrightarrow{zx}$. Tenemos que $f_k(\\overrightarrow{zx}) = c_k(\\overrightarrow{zx})$ y $f_{k+1}(\\overrightarrow{zx}) < c_{k+1}(\\overrightarrow{zx})$. Por lo tanto del paso k a k+1 DEVOLVEMOS flujo de x a z.\n",
        "\n",
        "En ambos casos la longitud del camino que usamos es mínima y por lo tanto\n",
        "\n",
        "$$d_k(z) = d_k(x)+1$$\n",
        "\n",
        "Pero entonces\n",
        "\n",
        "$$d_k(z) = d_k(x)+1 > (d_k(z) + 1) + 1$$\n",
        "$$ 0 > 2$$\n",
        "\n",
        "Absurdo, que vino de suponer que $A \\ne \\emptyset$. Por lo tanto $A = \\emptyset$\n"
      ],
      "metadata": {
        "id": "_4wPtmgGMi0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 3.Complejidad de Dinic\n",
        "\n",
        "¿Cuál es la complejidad del algoritmo Dinic? Probarla en ambas versiones: Dinitiz original y Dinic-Even (no hace falta probar que la distancia en NA sucecivos aumenta).\n",
        "\n",
        "## Definiciones\n",
        "\n",
        "### Flujo Bloqueante\n",
        "Si todo camino dirigido de s a t tiene al menos un lado saturado.\n",
        "\n",
        "### Networks auxiliares\n",
        "\n",
        "## Estructura\n",
        "* Enunciamos que la longitud de los sucesivos NA crece\n",
        "* Primero mostramos los aspectos generales de la complejidad de algoritmos \"tipo Dinic\"\n",
        "* Luego vemos cuánto cuesta conseguir un flujo bloquean en cada implementación (CFB)\n",
        "* Dinitz: vemos cuanto cuesta ver que borrar en cada poda ($O(n)$) + cuanto cuesta borrar en general ($O(2m)$)\n",
        "* Even: Planteamos que la corrida son palabras $A$ + $(R|I)$  y vemos cuantas palabras puede haber ($m$) y cuanto cuesta cada palabra ($O(n)$)\n",
        "* Ambas tienen entonces costo $O(n*m)$\n",
        "\n",
        "##Prueba\n",
        "\n",
        "Como sabemos que los NA crecen en longitud, tenemos que a lo sumo habra $n$ networks auxiliares.\n",
        "\n",
        "Luego también sabemos que la complejidad de construir un NA es la de BFS: $O(m)$ por lo tanto tenemos que la complejidad de un algoritmo tipo dinic es:\n",
        "\n",
        "$$n * (O(m) + CFB) = O(n * (m + CFB))$$ donde CFB es costo de hallar un flujo bloqueante en un NA.\n",
        "\n",
        "### Dinitz\n",
        "\n",
        "Para ver la complejidad de la versión de dinitz es necesario entonces ver el costo de CFB. CFB en dinitz va a consistir del costo de:\n",
        "\n",
        "* Hacer una búsqueda DFS\n",
        "* Podar antes de cada búsqueda\n",
        "\n",
        "La búsqueda tiene la propiedad de que nunca vamos a hacer backtracking, ya que hemos podado los deadends anteriormente. Por lo tanto el costo de buscar un camino en dinitz es $O(n)$.\n",
        "\n",
        "Como a lo sumo puede haber m caminos, tenemos que para hallar todos los caminos tenemos $O(n*m)$.\n",
        "\n",
        "Para analizar el costo de podar, debemos analizar no una sola poda sino todas las podas de un CFB en conjunto. De esta forma, podemos ver las podas como dos operaciones separadas:\n",
        "\n",
        "* Revisar los vértices de niveles más altos a más bajos para ver si borrarlos (PV)\n",
        "* Borrar los lados de un vértice x ($B(x)$)\n",
        "\n",
        "La complejidad de PV es $O(n)$ para una poda ya que solo mira los vértices. Entonces para la totalidad de podas tiene orden $O(n*m)$.\n",
        "\n",
        "La complejidad de $B(x)$, conviene verla en conjunto. Cada vez que se llama borra al menos un lado, luego la suma total es $O(m)$ porque en total hay $m$ lados.\n",
        "\n",
        "Por lo tanto la complejidad del CFB nos queda:\n",
        "\n",
        "$$ O(n*m) + O(n*m) + O(m) = O(n*m) $$\n",
        "\n",
        "Por lo tanto la complejidad de Dinitz es:\n",
        "\n",
        "$$ O(n * (m + (n*m))) = O(n * (n*m)) = O(n^2*m) $$\n",
        "\n",
        "### Even\n",
        "\n",
        "Para analizar la complejidad de even nos conviene dar el pseudocódigo:\n",
        "\n",
        "```python\n",
        "g = 0\n",
        "stopflag = 1\n",
        "while(stopflag)\n",
        "\tp = [s]\n",
        "\tx = s\n",
        "\twhile(x!=t) and (stopflag)\n",
        "\t\tif R+(x) != empty: avanzar(x)\n",
        "\t\telse if (x != s): retroceder(x)\n",
        "\t\telse: stopflag = 0\n",
        "\tif(x == t): incrementar()\n",
        "return g\n",
        "```\n",
        "Incrementar() es $O(n)$, avanzar y retroceder es $O(1)$.\n",
        "\n",
        "Si denotamos avanzar como A, retroceder como R e incrementar (inicializar la siguiente iteración) como I, entonces cada ejecución de CFB es una palabra que contiene As, Rs e Is.\n",
        "\n",
        "Cada corrida podemos separarla en segmentos en forma AAAA...X donde X puede ser R o I.\n",
        "\n",
        "En ambos casos (x = R ó I) se borra un lado al final de la palabra, por lo tanto hay a lo sumo $m$ palabras.\n",
        "\n",
        "La complejidad de cada palabra está dada por la cantidad de As y la complejidad de X. Como máximo podemos tener n As.\n",
        "\n",
        "Si X=R, entonces tenemos $O(n)$ por cada palabra ya que $O(n) + O(1) = O(n)$. Si X=I, entonces tenemos $O(n+n) = O(n)$ por cada palabra.\n",
        "\n",
        "Como por cada corrida hay a lo sumo $m$ palabras y el costo de cada una es $O(n)$, tenemos que la complejidad CFB en dinic-even es $O(n*m)$.\n",
        "Por lo tanto la complejidad de dinic-even es\n",
        "\n",
        "$$ O(n * (m + (n*m))) = O(n * (n*m)) = O(n^2*m) $$"
      ],
      "metadata": {
        "id": "VHIbQwxa61Gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 4.Complejidad de Wave\n",
        "\n",
        "¿Cuál es la complejidad de Wave? Probarla (no hace falta probar que la distancia en NA sucesivos aumenta)\n",
        "\n",
        "## Estructura\n",
        "\n",
        "* Dar pseudocódigo (Importante: se borran los vértices después de envíar/devolver en ciertos casos)\n",
        "* Acotar cantidad de olas: siempre bloqueamos a alguien en la ida\n",
        "* Separar en caso de envío y devolución (vértice a vértice)\n",
        "* Acotar ocurrencias en cada caso\n",
        "* Concluir la complejidad\n",
        "\n",
        "## Prueba\n",
        "\n",
        "```python\n",
        "g = 0\n",
        "\n",
        "# Inicializacion\n",
        "for x in E:\n",
        "\tD(x) = 0 # D(x) es in(x) - out(x) \"Desbalanceo hacia adelante\"\n",
        "\tB(x) = 0 # B(x) = \"esta bloqueado?\"\n",
        "for x in R+(s):\n",
        "\tg(sx) = c(sx)\n",
        "\tD(x) = c(sx)\n",
        "\tD(s) = -c(sx)\n",
        "\tM(x) = {s} # Registramos a s como alguien que me envia\n",
        "\n",
        "# Bucle principal\n",
        "\n",
        "while (D(t) + D(s) != 0)\n",
        "\t# Forward wave\n",
        "\tfor x in range(s+1, t-1)\n",
        "\t\tif(D(x) > 0): FB(x)\n",
        "\n",
        "\t# Backward wave\n",
        "\tfor x in range(s+1, t-1)\n",
        "\t\tif(D(x) > 0 and B(x)): BB(x)\n",
        "\n",
        "\n",
        "# Forward Balance \"Enviar flujo\"\n",
        "def FB(x):\n",
        "\twhile(D(x) > 0) and (R+(x).notEmpty())\n",
        "\t\ty = R+(x).get()\n",
        "\t\tif(B(y)): R+(x) -= y # Si esta bloqueado ya no le mandamos\n",
        "\t\telse:\n",
        "\t\t\tA = min(D(x),  c(xy) - g(xy)) # Cantidad a enviar, toda la que pueda dentro de mi desbalanceo\n",
        "\t\t\t# Actualizar flujo y desbalanceo\n",
        "\t\t\tg(xy) += A\n",
        "\t\t\tD(x) -= A\n",
        "\t\t\tD(y) += A\n",
        "\t\t\tM(y) = M(y) + x\n",
        "\t\t\t# Quitar de vecinos si esta lleno el lado\n",
        "\t\t\tif(g(xy) == c(xy)): R+(x) -= y\n",
        "\tif(D(x) > 0): B(x) = 1 # si no pudimos balancear, estamos bloqueados\n",
        "\n",
        "\n",
        "# Backward Balance \"Devolver flujo\"\n",
        "def BB(x):\n",
        "\twhile(D(x) > 0)\n",
        "\t\ty = M(x).get()\n",
        "\t\tA = min(D(x),  g(yx)) # Cantidad a devolver, toda la que pueda dentro de mi desbalanceo\n",
        "\t\tg(xy) -= A\n",
        "\t\tD(x) -= A\n",
        "\t\tD(y) += A\n",
        "\t\tif(g(yx) == 0): M(x) -= y # Si le devolvi todo, ya no me manda\n",
        "\n",
        "\n",
        "```\n",
        "Primero que nada acotemos la cantidad de olas. Cuando vamos hacia adelante siempre bloqueamos a un vértice. De no ser el caso, sería la última ola (pues si quedan todos balanceados, terminamos). Por lo tanto hay $O(n)$ olas. Solo podemos ir hacia atrás luego de ir hacia adelante, así que tambien hay $O(n)$ olas hacia atrás.\n",
        "\n",
        "La complejidad va a estar dada por:\n",
        "\n",
        "$$ S + P + V + Q $$\n",
        "\n",
        "donde:\n",
        "\n",
        "* S = cantidad de veces que envíamos de un $x$ a un $y$ y lo saturamos\n",
        "* P = cantidad de veces que envíamos de un $x$ a un $y$ sin saturar\n",
        "* V = cantidad de veces que devolvemos de un $x$ a un $y$ y lo vacíamos\n",
        "* Q = cantidad de veces que devolvemos de un $x$ a un $y$ y no lo vacíamos\n",
        "\n",
        "### S\n",
        "Sabemos que FB elimina a $y$ luego de envíarle flujo si lo hemos saturado. Esto es correcto ya que no volvemos a envíar flujo por ahí (está lleno el lado). Si en algún momento se vaciara por un BB desde $y$, entonces $y$ estaría bloqueado y tampoco habría que envíarle nada por ese lado. Por lo tanto $S \\le m$.\n",
        "\n",
        "### V\n",
        "Al igual que para S, cuando devolvemos por un lado y este lado se vacía. Entonces borramos a $y$ de $M(x)$. $y$ no le envía nada a $x$ ya que $x$ es un vértice bloqueado. Por lo tanto $V \\le m$.\n",
        "\n",
        "### P\n",
        "Cuando hacemos FB, solo el último que vemos es capaz de no ser saturado, ocurre a lo sumo una vez por FB. Por lo tanto $P \\le FB$ Hay a lo sumo $n-2$ FB por ola. P es entonces $O(n^2)$ ya que hay $O(n)$ olas y por ola hay $O(n)$ FB.\n",
        "\n",
        "### Q\n",
        "Cuando hacemos BB, solo un lado es capaz de no ser vaciado y por lo tanto hay a lo sumo uno solo por ola hacia atrás por vértice. Q es entonces $O(n^2)$.\n",
        "\n",
        "La complejidad de CFB:\n",
        "$$ S+V+P+Q = O(2*m+2*n^2) = O(n^2)$$\n",
        "\n",
        "La complejidad total de Wave es:\n",
        "\n",
        "$$ O(n) * O(n^2) = O(n^3) $$"
      ],
      "metadata": {
        "id": "Uh1MtmOn9nHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Distancia en NA sucesivos aumenta\n",
        "\n",
        "Dados dos networks auxiliares sucesivos, NA y NA', ya tenemos por la prueba de E-K que $d_f(s,x) \\le d_{f'}(s,x)$. Ahora queremos probar que ahí vale siempre un $<$.\n",
        "\n",
        "## Estructura\n",
        "* Asumir que en ambos networks llegamos a $t$, sino es trivial que la distancia aumenta\n",
        "* Hay un camino en NA' que no esta en NA, y hay dos formas que eso pase\n",
        "* Vemos que para cada forma que la distancia aumenta\n",
        "* Forma 1: Falta un vértice. $d_f(t) \\le d_f(x_i)$ y $d_{f'}(x_i) = i < r = d_{f'}(t)$\n",
        "* Forma 2: Falta un lado. Vemos que si falta el lado $\\overrightarrow{x_ix_{i+1}}$ tenemos dos casos, que sea $<$ o $=$. Se ve que $=$ no es por una ilegalidad en los niveles (se tendria que desaturar o hacerse no vacío en NA para que esté en NA' pero el lado para hacer eso es ilegal que esté en NA). Y vemos que $<$ si funciona por E-K y la hipotesis.\n",
        "\n",
        "## Prueba\n",
        "\n",
        "Si t $\\notin$ NA' terminamos porque es trivial.\n",
        "\n",
        "Asumamos entonces que t $\\in$ NA'. Entonces hay un camino dirigido $x_0,x_1,...x_{r-1},x_r$. Este camino $\\notin$ a NA, pues sino hubiera sido saturado y no podría estar en NA'.\n",
        "\n",
        "Puede haber dos razones por la que no esté en el NA:\n",
        "\n",
        "* Falta un vértice\n",
        "* Falta un lado\n",
        "\n",
        "### Caso 1: Falta un vértice\n",
        "\n",
        "Si un vértice $x_i$ no está, entonces sabemos que $x_i \\ne t$.\n",
        "\n",
        "La única forma que $x_i$ no esté en NA es que $d_f(t) \\le d_{f}(x_i)$. Al ser NA' un network por niveles, tenemos que $d_{f'}(x_i) = i$.\n",
        "\n",
        "Como $x_i \\ne x_r = t$, tenemos $d_f(t) \\le d_f(x_i) \\le d_{f'}(x_i) = i < r = d_{f'}(t)$.\n",
        "\n",
        "Por lo tanto hemos probado que en este caso la longitud aumenta.\n",
        "\n",
        "### Caso 2: Falta un lado\n",
        "\n",
        "Digamos que el primer lado que falta es $ \\overrightarrow{x_ix_{i+1}} $.\n",
        "\n",
        "Como es el primer lado que falta, entonces el camino $x_0,x_1,x_2,...,x_i$ si está en NA y por lo tanto $d_f(x_i) = i$.\n",
        "\n",
        "Por E-K, sabemos que $d_f(x_{i+1}) \\le d_{f'}(x_{i+1}) $.\n",
        "\n",
        "Asumamos el caso $d_f(x_{i+1}) = d_{f'}(x_{i+1}) = {i+1}$.\n",
        "\n",
        "En el NA, $x_i$ está en el nivel i y $x_{i+1}$ está en el nivel $i+1$. Concluimos que el lado $\\overrightarrow{x_{i+1}x_i}$ tampoco está en NA pues los niveles no lo permiten.\n",
        "\n",
        "El lado $ \\overrightarrow{x_ix_{i+1}} $ está a distancia \"legal\" pero no está en el NA, esto se puede deber a que $ \\overrightarrow{x_ix_{i+1}} $ es lado del N original pero está saturado ó $ \\overrightarrow{x_{i+1}x_i} $ es lado del N original pero está vacío.\n",
        "\n",
        "Pero $ \\overrightarrow{x_ix_{i+1}} $ está en el NA', entonces el lado se desaturo ó se hizo no vacío al construir el NA'.\n",
        "\n",
        "La única forma de que pase estó es que se envíe o devuelva flujo según el caso en el NA, pero para esto tendríamos que haber usado el lado $ \\overrightarrow{x_{i+1}x_i} $ en el NA, lo cual es un Absurdo por lo que mencionamos antes que no puede estar ese lado.\n",
        "\n",
        "Ahora asumamos el caso $d_f(x_{i+1}) < d_f'(x_{i+1})$.\n",
        "\n",
        "$$ d_f(t) = d_f(x_{i+1}) + b_f(x_{i+1}) \\le d_f(x_{i+1}) + b_{f'}(x_{i+1}) < d_{f'}(x_{i+1}) + b_{f'}(x_{i+1}) = d_{f'}(t)$$\n",
        "\n",
        "Por lo tanto $ d_f(t) < d_{f'}(t) $"
      ],
      "metadata": {
        "id": "v4TZ2RfShIxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 6.Max Flow Min Cut\n",
        "Probar que el valor de todo flujo es $\\le$ que la capacidadde todo corte ($v(f) \\le cap(S)$). Y si el f es un flujo, entonces las siguientes afirmaciones son equivalente:\n",
        "1. Existe un corte S tal que $v(f) = cap(S) = C(S, \\overline{S})$ (y en este caso , S es un minimal).\n",
        "2. f es maximal\n",
        "3. No existen f-CA\n",
        "\n",
        "(Puede usar sin necesidad de probarlo que si f es flujo y S un corte entonces $v(f) = f(S,\\overline{S}) - f(\\overline{S}, S)$)\n",
        "\n",
        "## Estructura\n",
        "\n",
        "Primero probamos $v(f) \\le cap(S)$ $\\forall$ f,s (f flujo y s corte) usando $v(f) = f(S,\\overline{S}) - f(\\overline{S},S)$\n",
        "\n",
        "Después probamos la equivalencia de esta forma: $ 1 => 2 => 3 => 1$. Y queda probada la ida y la vuelta entre todos.\n",
        "* $1 => 2$: $v(f) = cap(S) \\ge v(g)$ $\\forall$ flujo g\n",
        "* $2 => 3$: Suponer que existe un f-CA y ver que f no es maximal\n",
        "* $3 => 1$: Construimos $S$ y vemos que los límitrofes están saturados y que en $\\overline{S}$ lo limitrofes no envían nada hacia atrás por lo tanto $f(S,\\overline{S}) - f(\\overline{S},S) = C(S,\\overline{S}) - 0 = cap(S)$\n",
        "\n",
        "## Prueba\n",
        "\n",
        "Primero probamos $v(f) \\le cap(S)$:\n",
        "$$v(f) = f(S,\\overline{S}) - f(\\overline{S},S) \\le f(S,\\overline{S}) \\le C(S,\\overline{S}) = cap(S)$$\n",
        "\n",
        "Por lo tanto $v(f) \\le cap(S)$ $\\forall f$\n",
        "\n",
        "Veamos ahora la otra parte:\n",
        "\n",
        "* $1 => 2$: Por hipotesis tenemos que $v(f) = cap(S)$. Por la parte anterior tenemos que para todo g $v(g) \\le cap(S)$. Entonces $v(f) \\ge v(g)$ para todo g y por lo tanto f es maximal.\n",
        "\n",
        "* $2 => 3$: Si existiese un f-CA, podríamos mandar un $\\mathcal E > 0$ a través de él. Obtendriamos un flujo $f*$ tal que $v(f*) = v(f) + \\mathcal E$. Esto díria que $v(f*) > v(f)$ y contradice la hipotesis de que f sea maximal. Por lo tanto no existe un f-CA.\n",
        "\n",
        "* $3 => 1$: Definimos $S = \\{s\\} \\cup \\{x \\in V : \\text{exista un f-CA desde s a x}\\}$.\n",
        "\n",
        "Como suponemos el punto 3, entonces $t \\notin S$ lo que implica que S es un corte.\n",
        "\n",
        "Como f es un flujo y S un corte tenemos que $v(f) = f(S,\\overline{S}) - f(\\overline{S},S)$. Calculemos $f(S,\\overline{S})$ y $f(\\overline{S},S)$\n",
        "\n",
        "* $f(S, \\overline{S}) = \\sum_\\text{x $\\in$ S, y $\\notin$ S, $\\overrightarrow{xy} \\in$ E} f(\\overrightarrow{xy}) $\n",
        "\n",
        "Como  $y \\notin S$ no existe un f-CA entre s e y, pero como $\\overrightarrow{xy} \\in E$ podría ser un f-CA. Entonces la única razón por la cuál no es un f-CA es porque no podemos usar el lado $\\overrightarrow{xy}$ por estar saturado, es decir $f(\\overrightarrow{xy}) = C(\\overrightarrow{xy})$\n",
        "\n",
        "Entonces:\n",
        "\n",
        "$$ f(S,\\overline{S}) = \\sum f(\\overrightarrow{xy}) =\\sum C(\\overrightarrow{xy}) = cap(S,\\overline{S}) = cap(S)$$\n",
        "\n",
        "*  $f(\\overline{S}, S) = \\sum_\\text{x $\\notin$ S, y $\\in$ S, $\\overrightarrow{xy} \\in$ E} f(\\overrightarrow{xy}) $\n",
        "\n",
        "Al igual que antes como $x \\notin S$ no existe un f-CA entre s y x pero como $\\overrightarrow{xy} \\in E$ podría serlo usando y,x como lado backward. Entonces la única razón por la cuál no es un f-CA es porque no podemos usarlo como lado backward, es decir $f(\\overrightarrow{xy}) = 0$\n",
        "\n",
        "Entonces\n",
        " $$ f(\\overline{S},S) = \\sum f(\\overrightarrow{xy}) = \\sum 0 = 0 $$\n",
        "\n",
        " Por último $ v(f) = cap(S) - 0 = cap(S)$\n"
      ],
      "metadata": {
        "id": "kMuHqO_9qC4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 7.2-Color es Polinomial\n",
        "\n",
        "## Prueba\n",
        "\n",
        "Dado un grafo G, tomamos un vértice x cualquiera y lo coloreamos con 0 Luego, hacemos BFS y coloreamos cada vértice con 0 si su distancia a x es par, o 1 en caso contrario. En caso de que no sea un grafo conexo, hacemos lo mismo con otro x' que falte hasta terminar de colorear todos los vértices. Luego vemos si este coloreo es propio. Si lo es entonces G es bipartito, sino no.\n",
        "\n",
        "BFS es $O(m)$ lo que implica que es un algoritmo polinomial.\n",
        "\n",
        "Probemos ahora que el algoritmo es correcto:\n",
        "\n",
        "Si la respuesta es $\\mathcal X (G) \\le 2 $ entonces esa respuesta es correcta ya que es lo que hace el algoritmo.\n",
        "\n",
        "Veamos que pasa si la respuesta es $\\mathcal X (G) > 2$. Para esto tenemos que probar que no hay ningún coloreo con 2 colores. Entonces que si el coloreo no es propio, ningún otro coloreo con 2 colores es propio.\n",
        "\n",
        "Que el coloreo no sea propio $=>$ existe un $z,y$ ($z \\ne y$) tales que $c(z) = c(y)$ y $zy$ es un lado de G.\n",
        "\n",
        "Tomemos un camino entre $x$ y $z$ en BFS, y un camino entre $x$ e $y$ en BFS. Sea $w$ el último vértice en común. Miremos el ciclo $w...zy...w$ (en G) y calculemos la longitud.\n",
        "\n",
        "$$ Longitud  = d(w,z) + d(z,y) + d(y,w)$$\n",
        "\n",
        "Sacamos mod 2 y queda:\n",
        "\n",
        "$$ \\text{Longitud mod 2} = (d(w,z) + d(z,y) + d(y,w)) \\text{ mod 2} $$\n",
        "$$ = (d(w,z) + 1 + d(y,w)) \\text{ mod 2}$$\n",
        "\n",
        "Agregamos $ 2 * d(x,w)$ ya que su mod 2 es $= 0$ y no cambia el resultado:\n",
        "\n",
        "$$ (d(w,z) + 1 + d(y,w) + 2 * d(x,w)) \\text{ mod 2}$$\n",
        "$$ (d(x,z) + 1 + d(y,x)) \\text{ mod 2}$$\n",
        "\n",
        "Luego por BFS:\n",
        "\n",
        "$$ (c(z) + 1 + c(w)) \\text{ mod 2} = 1 \\text{ pues } c(z)=c(y)$$\n",
        "\n",
        "Por lo tanto es un clico impar y como G tiene un ciclo impar $\\mathcal X (G) \\ge 3$."
      ],
      "metadata": {
        "id": "5GPSYiRglNR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 8.Teorema de Hall\n",
        "Sea G un grafo bipartito con partes $X$ e $Y$, $|S| \\le |\\Gamma(S)|$  $\\forall S \\subseteq X$  si y solo si existe un matching completo sobre X.\n",
        "\n",
        "## Definiciones\n",
        "* Matching Perfecto: $V_M = V(G)$\n",
        "* Matching Completo: de $\\overline{\\underline{X}}$ a $\\overline{\\underline{Y}}$\n",
        "si $V_M \\cap \\overline{\\underline{X}}$. Si $|\\overline{\\underline{X}}| = |\\overline{\\underline{Y}}|$ entonces el matching es Perfecto.\n",
        "\n",
        "## Estructura\n",
        "\n",
        "* Para el lado $<=$: el matching induce a una función inyectiva $\\Phi$ de $\\overline{\\underline{X}}$ a $\\overline{\\underline{Y}}$ tal que $x\\Phi(x)$  $\\in$ $E_M$. Luego $|Γ(S)| \\ge |\\Phi(S)| = |S|$.\n",
        "* Para el lado $=>$: Vemos la contrarrecíproca y usamos lo que sabemos de E-K:\n",
        "* Separamos el corte minimal $C = {s} + S + T$ donde $S = C  \\cap \\overline{\\underline{X}}$  y $T = C \\cap \\overline{\\underline{Y}}$\n",
        "* E-K agrega primero $S_0$ y esos agregan a sus vecinos $T_1$\n",
        "* Luego los $T_1$ agregan a sus vecinos a la izquierda ($S_1$). Esto se da generalmente.\n",
        "* Sabemos $T ⊆ \\Gamma(S)$, er que $T = \\Gamma(S)$\n",
        "* Hacemos las cuentas y vemos que $|S| = |S_0| + |S-S_0| = |S_0| + |T| = |S_0| + |\\Gamma(S)| > |\\Gamma(S)|$\n",
        "\n",
        "## Prueba\n",
        "\n",
        "### ($<=$)\n",
        "Si existe un matching completo de $\\overline{\\underline{X}}$ a $\\overline{\\underline{Y}}$, el matching induce a una función inyectiva $\\phi$ que va de $\\overline{\\underline{X}}$ a $\\overline{\\underline{Y}}$ tal que $x\\Phi(x) \\in E$.\n",
        "\n",
        "Entonces $|Γ(S)| \\ge |\\Phi(S)| = |S|$.\n",
        "\n",
        "### ($=>$)\n",
        "\n",
        "Probemos por contrarrecíproca:\n",
        "\n",
        "Asumiendo que no hay matching completo, y sea $C$ el corte minimal que obtenemos al correr E-K, definimos:\n",
        "\n",
        "$$ S = C \\cap \\overline{\\underline{X}}$$\n",
        "$$ T = C \\cap \\overline{\\underline{Y}}$$\n",
        "\n",
        "Si pensamos en la última cola E-K que construye el algoritmo, tenemos $S_0$ los vértices en $S$ agregados por $s$, luego $T_1$ los vértices agregados por los vértices $S_0$, y en general $S_i$ agregado por $T_i$ que a su vez es agregado por $S_{i-1}$\n",
        "\n",
        "#### Observación 1\n",
        "Todos los $T_i$ agregan tantos vértices a la cola como vértices que tenga, por lo tanto $|T_i| = |S_i|$ para $i > 1$. Pues como no llegamos a t, entonces los vértices en $T_i$ tienen $out_f(y) = 1$, y por lo tanto, por el principio de preservación, $in_f(y)=1$. Entonces tienen exáctamente 1 vécino backward a quién devolverle flujo. A su vez sabemos que esté vécino no está en la cola con anterioridad, ya que si le está enviando a y, entonces $f(\\overrightarrow{sx}) = 1$ por lo tanto no es posible que esté en la cola agregado por s. Tampoco es posible que haya sido agregado por otro lado backward de otro $T_r$ con $r < i$ ya que en este caso tendríamos $out_f(x) = f(\\overrightarrow{xy_i}) + f(\\overrightarrow{xy_r}) = 2 \\ne in_f(x) = 1$.\n",
        "\n",
        "#### Observación 2\n",
        "\n",
        "$S$ es la unión de los $S_i$ y $T$ la unión de los $T_i$.\n",
        "\n",
        "#### Observación 3\n",
        "\n",
        "$ T = \\Gamma(S)$. Si no fueran iguales entonces existe un $y \\in \\Gamma(S)$ tal que $y \\notin T$. Como $y \\in \\Gamma(S)$ entonces existe un $x \\in S$ con $xy \\in E$. Luego $x$ nunca agregó a y ya que $y \\notin T$, por lo tanto $f(\\overrightarrow{xy}) = 1$. Pero entonces el único que puede agregar a x es s, estó implicaría que el $f(\\overrightarrow{sx}) = 0$, lo cuál es un absurdo porque $f(\\overrightarrow{xy}) = 1$. Por lo tanto $T = \\Gamma(S)$.\n",
        "\n",
        "Entonces tenemos:\n",
        "\n",
        "$$ |S| = |S_0 \\cup S_1 \\cup ... S_k| $$\n",
        "$$ = |S_0| + |S_1 \\cup ... \\cup S_k| $$\n",
        "$$ = |S_0| + |T| $$\n",
        "$$ = |S_0| + |\\Gamma(S)| $$\n",
        "$$ > |\\Gamma(S)| \\text{ ya} \\text{ que} |S_0| \\ne 0 $$\n",
        "\n",
        "Por lo tanto $|S| > |\\Gamma(S)|$ si no existe matching Perfecto. Entonces si existe matching Perfecto $|S| \\le |\\Gamma(S)|$"
      ],
      "metadata": {
        "id": "K4_f2uK0qRXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 9.Teorema de Konig (Matrimonio)\n",
        "\n",
        "Todo grafo bipartito regular tiene un matching Perfecto.\n",
        "\n",
        "## Estructura\n",
        "* Planteamos un subconjunto cualquiera $W ⊆ X$\n",
        "* Planteamos el conjunto de lados $ E_W = \\{zw : w \\in W\\}$\n",
        "* Vemos que para este conjunto, $|E_W| = \\sum_{w \\in W} d(w) = Δ * |W|$\n",
        "* Vemos que si $W = X, E_X = E$ y $|E| = \\Delta * |X| = Δ * |Y|$ y por lo tanto $|X| = |Y|$\n",
        "* Ahora basta probar que existe un matching completo, y será también perfecto\n",
        "* Vemos que si tomamos $S ⊆ X$, entonces cada lado $l \\in E_S$ también cumple $l \\in E_{Γ(S)}$\n",
        "* Por lo tanto $E_S ⊆ E_{\\Gamma(S)} => |E_S| \\le |E_{Γ(S)}|$\n",
        "* Por lo tanto $\\Delta * |S| \\le \\Delta * |\\Gamma(S)| => |S| \\le |\\Gamma(S)|$ y cumple la condición de Hall\n",
        "\n",
        "## Prueba\n",
        "Sea $W ⊆ X$ y $ E_W = \\{zw : w \\in W\\}$, tenemos que  $|E_W| = \\sum_{w \\in W} d(w)$, pues como no hay lados entre vértices de $W$, no estamos contandos lados dos veces. Como G es Regular, tenemos también que $|E_W| = \\Delta |W|$.\n",
        "\n",
        "Observemos que esto también se cumple para cualquier $W$ subconjunto de $Y$, pues vale todo lo que dijimos hasta ahora.\n",
        "\n",
        "Si consideramos que todos los lados en $E$ son de la forma $xy$, con $x \\in X$, vemos que $E_X = E$ y por ende que $|E| = \\Delta * |X|$. Devuelta, lo mismo vale para $Y$, entonces $|E| = \\Delta * |Y|$ y por  lo tanto $|X| = |Y|$.\n",
        "\n",
        "Tenemos entonces que si tuvieramos un matching completo de $X$ a $Y$, ese matching sería también perfecto. Basta ver que se cumple la condición de Hall.\n",
        "\n",
        "Consideramos $S ⊆ X$, tenemos que para todo $l \\in E_S$ , este lado es de la forma $xy$, donde $x \\in S$, $y \\in \\Gamma(S)$, y por lo tanto $l \\in E_{\\Gamma(S)}$. Entonces vemos que $E_S ⊆ E_{\\Gamma(S)}$.\n",
        "\n",
        "Tenemos entonces\n",
        "\n",
        "$$ |E_S| \\le |E_{\\Gamma(S)}|$$\n",
        "$$ Δ*|S| \\le Δ*|\\Gamma(S)| $$\n",
        "$$ |S| \\le |\\Gamma(S)|$$"
      ],
      "metadata": {
        "id": "l-fdRSThIbu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 10.G Bipartito => X'(G) = $\\Delta$\n",
        "\n",
        "Sea G un grafo bipartito, $\\chi'(G)=\\Delta$\n",
        "\n",
        "## Estructura\n",
        "* Probamos para G regular y no regular\n",
        "* Para el caso regular usamos el teorema del matrimonio y hacemos por inducción. Se colorean lados, se sacan y se vuelve aplicar lo mismo sucesivamente.\n",
        "* Para el caso no regular, mostramos que $G ⊆ H$ con $\\Delta(G)= \\Delta(H)$ y $H$ regular. Lo hacemos dando un $G'$ con $\\delta(G') = \\delta(G) + 1$, y de esa forma llegamos eventualmente a un grafo $H$, con $\\delta(H) = \\Delta(H)= \\Delta(G)$ que será regular\n",
        "* Como $G$ es subgrafo de $H$ , se puede colorear G con $\\Delta(G)$ coloreS\n",
        "\n",
        "## Prueba\n",
        "\n",
        "### Regular\n",
        "Supongamos primero que G es regular y probesmolo por inducción en $\\Delta$.\n",
        "\n",
        "Si  $\\Delta = 1$, entonces $G$ es una colección de lados disjuntos, y podemos colorearlos con el color 1.\n",
        "\n",
        "Ahora, para el caso inductivo, ($HI:\\chi'(G^*)=\\Delta(G^*)$), como $G$ es bipartito regular por el teorema del matrimonio, tenemos que existre un matching Perfecto. Si tomamos los lados de un matching Perfecto y los quitamos, entonces tenemos un $G^*$ grafo bipartito regular con $\\Delta(G^*) = \\Delta(G)-1$.\n",
        "\n",
        "Por HI, este grafo se puede colorear con $\\Delta(G)-1$ colores. Si usamos este coloreo para colorear $G$, y coloreamos los lados del matching con un nuevo color, entonces tenemos un coloreo de lados propio, pues los lados del matching no comparten vértices. Por lo tanto $\\chi'(G)=\\Delta(G)$.\n",
        "\n",
        "### No Regular\n",
        "\n",
        "Para el caso de $G$ no Regular, basta con probar que $\\forall$ grafo bipartito $G$ se puede incluir en un grafo bipartito $G'$ con $\\delta(G') = \\delta(G) + 1$.\n",
        "Iterando está construcción, podemos llegar a un grafo $H: \\delta(H) = \\Delta(H) = \\Delta(G)$, es decir a un grafo bipartito regular con $\\Delta$ igual a $\\Delta(G)$, con $G$ subgrafo de $H$. De esta forma $G$ se puede colorear con $\\Delta(G)$ colores.\n",
        "\n",
        "Sea $G$ grafo tal que $G = (X \\cup Y, E)$ podemos definir $G'$ como:\n",
        "\n",
        "$$ G' =(X' \\cup Y', E') $$\n",
        "donde\n",
        "$$ X' = X \\cup Y^* , Y' = Y \\cup X^*$$\n",
        "$$ E' = E \\cup \\{x'y' : xy \\in E\\} \\cup \\{xx' : d(x) < \\Delta(G)\\} \\cup \\{yy' : d(y) < \\Delta(G)\\}$$\n",
        "donde $X^*$ e $Y^*$ son \"copias\" de $X$ e $Y$ ($x'$ es copia del vértice $x \\in X$).\n",
        "\n",
        "Este nuevo grafo $G'$ tiene como subgrafo a $G$. Pero también tiene que para cada vértice de $G$ cuyo grado sea menor a $\\Delta(G)$, ahora su grado es aumentado en 1: $\\delta(G') = \\delta(G) + 1$. También, como no hay lados entre\n",
        "vértices de $X'$ con $X'$ y lo mismo $Y'$, tenemos que $G'$ es bipartito.\n",
        "\n",
        "Concluimos que existe $H$ regular con $\\Delta(H) = \\Delta(G)$ y con $G$ subgrafo de este. Por lo  tanto se puede colorear a $G$ con $\\Delta(G)$ colores."
      ],
      "metadata": {
        "id": "TfjyUDPmIhc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 11.Complejidad de Hungaro\n",
        "\n",
        "Probar complejidad $O(n^4)$ y dar una idea de como se le puede reducir a $O(n^3)$.\n",
        "\n",
        "## Prueba\n",
        "### Idea globar del costo\n",
        "Con el método que hacemos en papel, usamos E-K sobre la matriz para ir aumentado el matching inicial. Esto lo vamos a hacer a lo sumo $n$ veces (pues hay $n$ lados en el matching perfecto que buscamos).\n",
        "\n",
        "Como el matching inicial cuesta $O(n^2)$ (que es lo que cuesta restarle el mínimo a cada fila, el mínimo a cada columna y obtener el matching inicial de ceros). Luego haremos $O(n)$ extensiones a este matching. La complejidad total del Húngaro es:\n",
        "\n",
        "$$ O(n^2) + O(n) * (\\text{complejidad de extender el matching en un lado})$$\n",
        "\n",
        "La complejidad de extender en un lado el matching, si es que ignoramos la complejidad de cambiar de matriz, es de $O(m)$ pues es la búsqueda de un CA con el $BFS$ de E-K si lo hacemos con colas, lo cuál seria $O(n^2)$ en estos casos ($m = O(n^2)$ ya que son matrices).\n",
        "\n",
        "Luego si la complejidad de cambiar de matriz es $CM$ y tenemos que hacer un máximo de $T$ cambios de matriz para agregar un lado, entonces la complejidad es:\n",
        "\n",
        "$$ O(n^2) + O(n) * (O(n^2)+ CM * T) $$\n",
        "\n",
        "Aclaración: Los cambios de matriz están entre medio de cada búsqueda, por eso es una suma entre la búsqueda BFS y los cambios de matriz, y no una multiplicación.\n",
        "\n",
        "### CM\n",
        "Consiste en:\n",
        "* Calcular $m$\n",
        "* Restar $m$ de $S$ y sumarlo a $\\Gamma(S)$\n",
        "\n",
        "Calcular $m$ consiste de calcular el mínimo de los elementos de $S\\space x\\space \\overline{\\Gamma(S)}$ así que es $O(n^2)$. Restar m de cada fila es $O(n)$ y por lo tanto de las filas de $S$ $O(n^2)$. Sumarlo a $\\Gamma(S)$ es $ O(n^2)$.\n",
        "\n",
        "Por lo tanto la complejidad de $CM$ es $O(n^2) + O(n^2) = O(n^2)$.\n",
        "\n",
        "### T\n",
        "Ahora vemos de acotar $T$.\n",
        "\n",
        "* Propiedad clave: Después de un cambio de matriz, o crecen las filas etiquetadas, o extendemos el matching (o ambas).\n",
        "\n",
        "Esto se ve cuando hacemos la nueva matriz donde $m = C_{x,v}$, y hay un nuevo $0$ en la entrada $C_{x,v}$. Por lo tanto cuando revisemos las filas, $x$ etiquetara a $v$. Si $v$ está libre extendemos el matching. Si $v$ no está libre, entonces agrega a alguna fila $z$ y quizás extendemos el matching. Si terminamos no pudiendo extender el matching, entonces tenemos que $S$ crece en al menos $1$ (el z que agregamos).\n",
        "\n",
        "Con esta propiedad tenemos que $T \\le n$.\n",
        "\n",
        "### Conclusión\n",
        "$$ O(n^2) + O(n) * (O(n^2) + O(n^2) * O(n)) $$\n",
        "$$ = O(n^4) $$\n",
        "\n",
        "### Complejidad mejorada: $O(n^3)$\n",
        "Dada la cuenta de arriba, vemos que si $CM$ costara $O(n)$, entonces tendríamos complejidad de $O(n^3)$. Para lograr esto, podemos hacer que calcular $m$ sea $O(n)$ y restar a las filas de $S$ y sumas a las columnas $\\overline{\\Gamma(S)}$ sea $O(n)$.\n",
        "\n",
        "Para lo primero, podemos tener pre-calculado el mínimo de cada fila $S$, por ejemplo, estó se podría hacer cuando se está revisando la fila para etiquitar las columnas. Los valores pre-calculados lo guardamos en un arreglo $mS[v]$, y si $C_{x,v}  < mS[v]$ actualizamos los $mS[v]$ y lo volvemos igual a $C_{x,v}$. También, para no tomar ceros, al $m$ lo calculamos de la siguiente forma: $min\\{mS[v] : mS[v]  \\ne 0\\}$.\n",
        "\n",
        "Para lo otro, podemos en lugar de restar/sumar a todas las entradas, mantener un un array con los valores que habría que sumarle/restarle a cada fila y columna. El costo va a ser $O(n)$ ya que es actualizar los arrays. Luego al buscar ceros en lugar de la guarda:\n",
        "$$if C_{x,v} == 0$$\n",
        "hacemos\n",
        "$$ if /(C_{x,v} - RF[x] + SC[v] == 0)$$\n",
        "\n",
        "La complejidad final queda:\n",
        "$$O(n^2) + O(n) * (O(n^2) + O(n) * O(n)$$\n",
        "$$ = O(n^3)$$\n",
        "\n"
      ],
      "metadata": {
        "id": "plRRgvVSaLoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 12.Cota de Hamming\n",
        "Sea C un código de longitud n que corrige $t = \\frac{\\delta - 1}{2}$ errores, entonces $|C| \\le \\frac{2^n}{\\sum_{k=0}^t {n \\choose k}}$.\n",
        "\n",
        "## Definiciones\n",
        "### Distancia de Hamming:\n",
        "$d_H(x,y) =$ # de bits de diferencia entre x e y\n",
        "\n",
        "### $\\delta(C)$\n",
        "$\\delta(C) = \\delta = Min \\{d_H(x,y) : x,y \\in C, x \\ne y\\}$\n",
        "\n",
        "## Estructura\n",
        "* Primero planteamos la idea de \"bola alrededor de una palabra del código\" ($B_i$)\n",
        "* Después vemos que si $A = \\cup_{i=1}^{|C|} B$, entonces $|C| = \\frac{|A|}{|B|}$\n",
        "* Calculamos $|B|$ y vemos que $|A| = 2^n$\n",
        "* Concluimos la cota\n",
        "\n",
        "## Prueba\n",
        "Sea\n",
        "$$ B_i = \\{w : w \\in \\{0,1\\}^n \\land d(v_i,w)\\le t\\} $$\n",
        "donde $v_i$ es la i-ésima palabra del código. También podemos verlo como una bola de radio t alredor de una palabra del código.\n",
        "\n",
        "Sea $A = \\cup_{i=1}^{|C|}B_i$, y tenemos que las $B_i$ son disjuntas, pues de no serlo el código no corregiría $t$ errores (ya que $t= \\frac{\\delta(C)-1}{2}$). Además, como $C$ corrige $t$ errores, en cada $B_i$ hay una única palabra del código. Además tenemos que todas las $B_i$ tienen el mismo tamaño (radio $t$).\n",
        "\n",
        "En conclusión:\n",
        "\n",
        "$$ |A| = |\\cup_{i=1}^{|C|}B_i| \\stackrel{\\text{$B_i$ son disjuntas}}= \\sum_{i=1}^{|C|} |B_i| \\stackrel{\\text{$B_i$ de igual cardinal}}= |C||B| $$\n",
        "\n",
        "Osea que tenemos\n",
        "\n",
        "$$ |A| = |C| * |B| $$\n",
        "$$ |C| = \\frac{|A|}{|B|}$$\n",
        "\n",
        "Si pensamos en $|B|$, vemos que lo podemos ver en capas de $0$ a $t$ palabras. En la capa $k-ésima$, las palabras varían en $k$ dígitos del centro (la palbra que si pertenece al código). Por lo tanto tenemos que $|B| = \\sum_{k=0}^t {n \\choose k}$.\n",
        "\n",
        "Como sabemos que $A \\subseteq \\{0,1\\}^n$, tenemos que $|A| \\le |\\{0,1\\}^n | = 2^n$.\n",
        "\n",
        "En conclusión:\n",
        "\n",
        "$$ |C| = \\frac{|A|}{\\sum_{k=0}^t{n \\choose k}} \\le \\frac{2^n}{\\sum_{k=0}^t{n \\choose k}} $$"
      ],
      "metadata": {
        "id": "c_6eFhM-Nk-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 13.$\\delta$ Columnas de H\n",
        "\n",
        "Probar que si $H$ es matriz de chequeo de $C$, entonces\n",
        "$$ \\delta(C) = Min\\{j : \\text{existe un conjunto de j columnas LD de H}\\} $$\n",
        "\n",
        "## Definiciones\n",
        "* $C$ lineal $=>$ $\\delta(C) = Min\\{||x|| : x \\ne 0, x \\in C\\}$\n",
        "* $C = Nu(H) = \\{y \\in \\{0,1\\}^n : H*y = 0\\} $\n",
        "\n",
        "## Estructura\n",
        "* Probaremos que $delta(C) \\le S$ y luego que $S \\le \\delta(C)$, donde $S = Min \\{j : \\text{existe un conjunto de j columnas LD de H}\\}$.\n",
        "* Para $S \\le \\delta(C)$, tenemos $c_1H^{(j_1)} + c_2H^{(j_2)} + ... + c_SH^{(j_S)} = 0$ y $ w = c_1e_{j_1} + c_2e_{j_2} + ... + c_Se_{j_s}$.\n",
        " Luego ver que $Hw^t = 0$ , por lo tanto $w \\in C = Nu(H)$. Luego $\\delta(C) = Min\\{||x|| : x \\ne 0, x \\in C\\} \\le  ||w|| \\le S$\n",
        "* Para $\\delta(C) \\le S$, $\\delta(C) = ||v||$ con $v \\in C$, entonces $Hv^t = 0$. Luego $ S \\le \\delta(C)$.\n",
        "\n",
        "## Prueba\n",
        "\n",
        "Sea $S = Min \\{j: \\text{existe un conjunto de j columnas LD de H} \\}$.\n",
        "\n",
        "Probaremos $S \\le \\delta(C)$ y $\\delta(C) \\le S$.\n",
        "\n",
        "### $\\delta(C) \\le S$\n",
        "\n",
        "Por definición de $S$, existe $c_1H^{j_1} + c_2H^{j_2}+ ... + c_SH^{j_S} = 0$ con $c_1, c_2, ..., c_S$ no todos nulos. Sea $w = c_1e_{j_1} + c_2e_{j_2} + ... + c_Se_{j_S}$, donde $e_j$ es el vector con todos $0$ salvo un $1$ en la coordenada $j$. Luego $w \\ne 0$ por $c_1,...c_S$ no todos nulos.\n",
        "\n",
        "$$Hw^t = H * (c_1e_{j_1} + c_2e_{j_2} + ... + c_Se_{j_S})$$\n",
        "$$ = c_1He_{j_1} + c_2He_{j_2} + ... + c_SHe_{j_S} $$\n",
        "$$ = c_1H^{j_1} + c_2H^{j_2} + ... + c_SH^{j_S}$$\n",
        "$$ = 0 $$\n",
        "\n",
        "Por lo tanto, $w \\in C$, pues $C = Nu(H)$. Pero su peso es $\\le S$.\n",
        "\n",
        "Luego $\\delta(C) = Min \\{||x|| : x \\ne 0, x \\in C \\} \\le ||w|| \\le S$, por lo tanto  $\\delta(C) \\le S$.\n",
        "\n",
        "### $S \\le \\delta(C)$\n",
        "\n",
        "Sea $v \\in C$ tal que  $\\delta(C) = ||v||$ y  $v= c_1e_{i_1} + c_2e_{i_2} + ... + c_{\\delta(C)}e_{i_\\delta(C)}$. Como $v \\in C$, entonces $Hv^t = 0$.\n",
        "\n",
        "$$ 0 = Hv^t = H^{(i_1)} + H^{(i_2)} + ... + H^{(i_\\delta(C))}$$\n",
        "\n",
        "Lo que significa que $\\{H^{(i_1)} + H^{(i_2)} + ... + H^{(i_\\delta(C))}\\}$ es un conjunto LD de columnas de H. Por lo tanto $ S \\le \\delta(C)$."
      ],
      "metadata": {
        "id": "6TsywXT3IXjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 14.Teorema de códigos cíclicos\n",
        "Sea $C$ un código cíclico de dimensión $k$ y longitud $n$ y sea $g(x)$ su polinimio generador. Probar que:\n",
        "\n",
        "$(i)$  $C$ está formado por los múltiplos de $g(x)$ de grado menor que $n$:\n",
        "$$ C = \\{p(x): gr(p) < n \\space \\land g(x)|p(x) \\}$$\n",
        "\n",
        "$(ii)$ $ C = \\{v(x) \\odot g(x) : v \\text{ es un polinomio cualquiera}\\}$\n",
        "\n",
        "$(iii)$ $gr(g(x)) = n -k$\n",
        "\n",
        "$(iv)$ $g(x)|(1+x^n)$\n",
        "\n",
        "## Definiciones\n",
        "\n",
        "* $k$ longitud de mensaje ($dimension$),$n$ longitud de palabra\n",
        "* Polinomio generador $g(x)$: único polinomio no nulo de grado mínimo\n",
        "* Sea $w(x) \\in C$ y $v(x)$, entonces $w(x) \\odot v(x) \\in C$ y $= w(x) * v(x) mod (1+x^n)$\n",
        "\n",
        "## Estructura\n",
        "* Se prueba 1 y 2 juntos. Vemos que $C_2 \\subseteq C$, luego $C ⊆ C_1$ y  por último $C_1 ⊆ C_2$.\n",
        "* Para el 3 vemos que por $C_1$ $gr(q) < n - gr(g)$. Luego $ |C| = 2^{n-gr(g)}$ y $|C| = 2^k$, entonces $k = n - gr(g) => gr(g) = n - k$.\n",
        "* Para el 4, $1+x^n = q(x)*g(x) + r(x)$, luego $r(x) = q(x) \\odot g(x)$. Entonces $gr(r) < gr(g)$ por lo tanto $r(x) = 0$ y $g(x)|(1+x^n)$.\n",
        "\n",
        "## Prueba\n",
        "\n",
        "### i) y ii)\n",
        "Sean $C_1 = \\{p(x): gr(p) < n \\space \\land g(x)|p(x) \\}$ y $ C_2 = \\{v(x) \\odot g(x) : v \\text{ es un polinomio cualquiera}\\} $.\n",
        "\n",
        "Tenemos la propiedad: $w \\in C => w \\odot v \\in C$. Por lo tanto $C_2 ⊆ C$.\n",
        "\n",
        "Veamos ahora $C ⊆ C_1$.\n",
        "\n",
        "Sea $p(x) \\in C$, tenemos que $gr(p) < n$. Aplicando el algoritmo de división de polinomios, tenemos:\n",
        "\n",
        "$$ p(x) = q(x) * g(x) + r(x) \\space \\space, \\space gr(r) < gr(g) < n $$\n",
        "\n",
        "por lo tanto\n",
        "\n",
        "$$ r(x) = p(x) + q(x) * g(x) $$\n",
        "\n",
        "Como $gr(p) < n$ ,  $p(x)\\space mod \\space (1+x^n) = p(x)$\n",
        "\n",
        "Como $gr(r) < n$ ,  $r(x)\\space mod \\space (1+x^n) = r(x)$\n",
        "\n",
        "Entonces\n",
        "$$ r(x) = r(x) \\space mod \\space (1+x^n) $$\n",
        "$$ = (p(x) + q(x) *g(x)) \\space mod \\space (1+x^n)$$\n",
        "$$ = p(x) + q(x) \\odot g(x) $$\n",
        "\n",
        "Como ambos términos son parte del código, $r(x)$ es parte del código. Pero si es parte del código, y tenemos que $gr(r) < gr(g)$ entonces $ r(x) = 0$, pues $g$ es el polinomio no nulo de menor grado en $C$.\n",
        "\n",
        "Por lo tanto $p(x) = q(x) * g(x) \\in C_1$, entonces concluimos que $C ⊆ C_1$.\n",
        "\n",
        "Ahora resta er que $C_1 ⊆ C_2$.\n",
        "\n",
        "Digamos que $p(x) \\in C_1$, entonces:\n",
        "\n",
        "$$ p(x) = p(x) \\space mod \\space (1+x^n) $$\n",
        "$$= q(x) * g(x) \\space mod \\space (1+x^n) $$\n",
        "$$= q(x) \\odot g(x) $$\n",
        "\n",
        "Por lo tanto $C_1 \\in C_2$.\n",
        "\n",
        "\n",
        "### iii)\n",
        "Por $(i)$ tenemos:\n",
        "\n",
        "$$ C = \\{q(x) * g(x): gr(q * g) < n \\}$$\n",
        "$$ = \\{q(x) * g(x): (gr(q) +  gr(g)) < n \\} $$\n",
        "$$ = \\{q(x) * g(x): gr(q) < n - gr(g) \\} $$\n",
        "\n",
        "Entonces\n",
        "\n",
        "$$ |C| = |\\{q(x) * g(x): gr(q) < n - gr(g) \\}|  = 2^{n-gr(g)}$$\n",
        "\n",
        "Pero $|C| = 2^k$, entonces $k = n - gr(g) => gr(g) = n - k$.\n",
        "\n",
        "### iv)\n",
        "\n",
        "Aplicamos algoritmo de división y despejamos el resto $r(x)$:\n",
        "\n",
        "$$ 1 + x^n = q(x) * g(x) + r(x) $$\n",
        "$$ r(x) = q(x) * g(x) + (1 + x^n) $$\n",
        "\n",
        "Si tomamos mod $(1+x^n)$, tenemos\n",
        "\n",
        "$$ r(x) \\space mod \\space (1 + x^n) = (q(x) * g(x) + (1 +x^n)) \\space mod \\space (1 + x^n)$$\n",
        "\n",
        "$$ r(x) = q(x) \\odot g(x)$$\n",
        "\n",
        "Por lo tanto tenemos que $r(x)$ está en el código y que $gr(r) < gr(g)$, y por lo tanto $r(x) = 0$.\n",
        "\n",
        "Lo que implica que $g(x) | (1+x^n)$."
      ],
      "metadata": {
        "id": "Cylu-q79dqVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 15.3-SAT es NP-completo\n",
        "\n",
        "##Prueba\n",
        "\n",
        "Veremos que $SAT \\le_p 3-SAT$.\n",
        "\n",
        "Sea $B$ en forma conjuntiva normal (CNF) tal que $ B = D_1 \\wedge D_2 \\wedge ... \\wedge D_r$ con $D_j = l_{1,j} \\vee l_{2,j} \\vee ... \\vee \\space l_{i,j} $ con $l_{r,j}$ literales.\n",
        "\n",
        "Queremos construir $\\tilde{B}$ polinomialmente tal que $\\tilde B$ este en CNF con 3 literales por disjunción tal que $B$ sea satisfacible si y sólo si $\\tilde B$ es satisfacible.\n",
        "\n",
        "Definimos unos $E_j$ y $\\tilde B = E_1 \\wedge ... ∧ E_n$. Con cada $E_j$ definido a partir de $D_j$ y de la cantidad de literales $r_j$ presentes en $D_j$, entonces:\n",
        "\n",
        "* Si $r_j = 3$ tenemos que $E_j = D_j$, por lo que no hago nada.\n",
        "* Si $r_j < 3$ agregamos variables mudas que no afectan al resultado, vemos los casos:\n",
        "\n",
        "  * $r_j = 2: $\n",
        "  $$D_j = l_{1,j} \\vee l_{2,j}$$\n",
        "  $$ E_j = (l_{1,j} \\vee l_{2,j} \\vee y_{1,j}) ∧ (l_{1,j} \\vee l_{2,j} \\vee \\overline{y}_{1,j}) $$\n",
        "\n",
        "  * $r_j = 1$:\n",
        "  $$ D_j = l_{1,j}$$\n",
        "  $$ E_j = (l_{1,j} \\vee y_{1,j} \\vee y_{2,j}) ∧ (l_{1,j} \\vee \\overline y_{1,j} \\vee y_{2,j}) ∧ (l_{1,j} \\vee y_{1,j} \\vee \\overline y_{2,j}) ∧ (l_{1,j} ∨ \\overline y_{1,j} ∨ \\overline y_{2,j}) $$\n",
        "\n",
        "* Si $r_j > 3:$\n",
        "$$ D_j = l_{1,j} ∨ l_{2,j} ∨ ... \\vee \\space l_{r_j,j}$$\n",
        "$$ E_j = (l_{1,j} ∨ l_{2,j} \\vee y_{1,j}) \\space ∧ (l_{3,j} ∨ \\overline y_{1,j} \\vee y_{2,j}) \\space ∧ (l_{4,j} ∨ \\overline y_{2,j} \\vee y_{3,j}) \\space ∧ ... ∧ (l_{r_j-2,j} ∨ \\overline y_{r_j-4,j} \\vee y_{r_j-3,j}) \\space ∧ (l_{r_j-1,j} ∨ l_{r_j,j} \\vee \\overline y_{r_j-3,j}) $$\n",
        "\n",
        "\\\n",
        "Son variables booleanas, para evaluarlas se elige un vector de 0's y 1's.\n",
        "\n",
        "Supongamos $\\tilde B$ satisfacible, denotamos $\\tilde B (\\overrightarrow x, \\overrightarrow y)$ y $B(\\overrightarrow x)$ ya que $\\tilde B$ depende de variables $x_1,...,x_algo$ e $y_{i,j}$ mientras que $B$ solo de las $\\overrightarrow x$. Es decir:\n",
        "\n",
        "$$ B = D_1 ∧ ... ∧ D_n \\rightarrow \\tilde B = E_1 ∧ ... ∧ E_n $$\n",
        "\n",
        "Vamos a demostrar que $∃ B(\\overrightarrow a) = 1 ⇔ ∃ \\overrightarrow a, \\overrightarrow b : \\tilde B (\\overrightarrow a, \\overrightarrow b) = 1$.\n",
        "\n",
        "## $(<=)$\n",
        "Supongamos que $\\tilde B(\\overrightarrow a, \\overrightarrow b) ⇒  B(\\overrightarrow a) = 0$ y lleguemos a un Absurdo.\n",
        "\n",
        "Como $B = D_1 ∧ ... ∧ D_n$ entonces $∃ j : D_j (\\overrightarrow a) = 0$, pero $D_j = l_{1,j} \\vee l_{2,j} \\vee ... \\vee  \\space l_{r_j,j}$ donde todos los términos tienen que ser cero. Entonces, $l_{i,j}(\\overrightarrow a) = 0 \\space \\forall i \\space \\text{(y ese j)}$.\n",
        "\n",
        "Por otro lado $\\tilde B (\\overrightarrow a, \\overrightarrow b) = 1 ⇒ ∃_j(\\overrightarrow a, \\overrightarrow b) = 1 \\space \\forall j$, en particular para el $j$ mencionado antes.\n",
        "\n",
        "Ahora veamos los casos:\n",
        "\n",
        "* Si $r_j = 3$, tenemos que $E_j = D_j$ asi que esto es imposible.\n",
        "$$ D_j(\\overrightarrow a) = 0 ⇒ E_j = 0 ⇒ \\tilde B (\\overrightarrow a, \\overrightarrow b) = 0  \\space \\text{Absurdo}$$\n",
        "\n",
        "* Si $r_j = 2$ tenemos que $E_j = (l_{1,j} \\vee l_{2,j} \\vee y_j) ∧ (l_{1,j} \\vee l_{2,j} \\vee \\overline y_j)$ pero $l_{i,j}(\\overrightarrow a) = 0$ entonces\n",
        "\n",
        "$$ 1 = E_j(\\overrightarrow a, \\overrightarrow b) $$\n",
        "$$ = (0 \\vee 0 \\vee y_j(\\overrightarrow b)) ∧ (0 \\vee 0 \\vee \\overline y_j(\\overrightarrow b))$$\n",
        "$$ = y_j(\\overrightarrow b) ∧ \\overline y_j(\\overrightarrow b)$$\n",
        "$$ = 0 \\space \\text{Absurdo}$$\n",
        "\n",
        "* $r_j = 1$\n",
        "$$ 1 = E_j(\\overrightarrow a, \\overrightarrow b) = l_{1,j} \\vee y_{1,j} \\vee y_{2,j}) ∧ (l_{1,j} \\vee \\overline y_{1,j} \\vee y_{2,j}) ∧ (l_{1,j} \\vee y_{1,j} \\vee \\overline y_{2,j}) ∧ (l_{1,j} ∨ \\overline y_{1,j} ∨ \\overline y_{2,j}) [\\overrightarrow a, \\overrightarrow b]$$\n",
        "$$ = (p \\vee q) ∧ (\\overline p \\vee q) ∧ (p \\vee \\overline q ) ∧ (\\overline p \\vee \\overline q)$$\n",
        "$$ = 0 \\space \\text{Absurdo}$$\n",
        "\n",
        "* $r_j > 3$\n",
        "$$ 1 = E_j = (l_{1,j} ∨ l_{2,j} \\vee y_{1,j}) \\space ∧ (l_{3,j} ∨ \\overline y_{1,j} \\vee y_{2,j}) \\space ∧ (l_{4,j} ∨ \\overline y_{2,j} \\vee y_{3,j}) \\space ∧ ... ∧ (l_{r_j-2,j} ∨ \\overline y_{r_j-4,j} \\vee y_{r_j-3,j}) \\space ∧ (l_{r_j-1,j} ∨ l_{r_j,j} \\vee \\overline y_{r_j-3,j}) [\\overrightarrow a, \\overrightarrow b]$$\n",
        "\\\n",
        "Sabemos que $l_{i,j}(\\overrightarrow a) = 0$\n",
        "\n",
        "Si $p_i = y_{i,j}(\\overrightarrow b)$ entonces $p_1 = 1 ⇒ p_2 = 1$ ya que $\\overline p_1 \\vee p_2 = 1$ y así sucesivamente. Entonces $\\overline p_{r_j-4} \\vee p_{j_r-3} = 1 ⇒ p_{r_j-3} = 1 $ y queda el término $\\overline p_{r_j-3} = 0$. La conjunción es entonces $1 ∧ 1 \\wedge ... ∧ 1 ∧ 0 = 0$ y por lo tanto $ 1 = 0 \\space \\text{Absurdo}$.\n",
        "\n",
        "## $(=>)$\n",
        "\n",
        "Si $∃ \\overrightarrow a : B(\\overrightarrow a) = 1 ⇒ ∃ \\overrightarrow b : \\tilde B(\\overrightarrow a, \\overrightarrow b) = 1$\n",
        "\n",
        "Para $r_j \\le 3$ se le puede dar cualquier valor a los $y_{i,j}$ por ejemplo $0$ y es trivial ver los casos $r_j = 1$ y $r_j = 2$.\n",
        "\n",
        "El único problema grande es $r_j > 3$.\n",
        "\n",
        "Como $B(\\overrightarrow a) = 1$ entonces $D_j(\\overrightarrow a) = 1$ (al menos un $l_{i,j}$ es $1$ para ese $j$). Entonces, $\\exists i_j : l_{i_j,j}(\\overrightarrow a) = 1$. Si hay más de uno, tomo cualquiera, por ejemplo el primero.\n",
        "\n",
        "Evaluamos los $y_{i,j}$ de forma tal que:\n",
        "$$ y_{i,j} (\\overrightarrow b)  = 1 \\text{ si }  i = 1, ... , i_j-2 $$\n",
        "$$ y_{i,j} (\\overrightarrow b)  = 0 \\text{ si }  i \\ge i_j-1 $$\n",
        "\n",
        "Entonces, si evaluamos tenemos:\n",
        "\n",
        "$$ E_j(\\overrightarrow a, \\overrightarrow b) =$$\n",
        "$$ = (l_{1,j} ∨ l_{2,j} \\vee \\underbrace{y_{1,j}}_{=1}) \\space ∧ (l_{3,j} ∨ \\overline y_{1,j} \\vee \\underbrace{y_{2,j}}_{=1}) \\space ∧ ... ∧ (l_{i_j-1,j} ∨ \\overline y_{i_j-3,j} \\vee \\underbrace{y_{i_j-2,j}}_{=1}) \\space ∧ (\\underbrace{l_{i_j,j}}_{=1} ∨ \\overline y_{i_j-2,j} \\vee y_{i_j-1,j}) ∧ ({l_{i_j+1,j}} ∨ \\underbrace {\\overline y_{i_j-1,j}}_{=1} \\vee y_{i_j,j}) \\space ∧ ...$$"
      ],
      "metadata": {
        "id": "3lkW_aplP4eB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 16.3-Color es NP-completo\n",
        "\n",
        "## Prueba\n",
        "\n",
        "Veremos que $3-SAT \\le_p 3-Color$. Es decir dada una expresión booleana $B$ en CNF con 3 literales por disjunción, debemos construir polinomialmente un grafo $G$ tal que se cumpla que:\n",
        "$$ B \\text { es satisfacible } ⇔ \\chi(G) \\le 3 $$\n",
        "\n",
        "Suponemos $B = D_1 ∧ ... ∧ D_m$ con variables $x_1, ... , x_n$ y $D_j = l_{1,j} \\vee l_{2,j} \\vee l_{3,j}$ (por ser $3-SAT$ esto queda fijo).\n",
        "\n",
        "\\\n",
        "Construcción polinomialmente del grafo $G$:\n",
        "\n",
        "* Vértices: $\\{s,t\\} \\cup \\{v_l : l \\text{ es literal}\\} \\cup \\{ a_{i,j}, e_{i,j} \\}_{i=1,2,3, j = 1,...,m}$ donde $\\{v_l : l \\text { es literal} \\}$ es equivalente a $\\{ v_{x_1}, v_{x_2},...,v_{x_n},v_{\\overline x_1},v_{\\overline x_2},..., v_{\\overline x_n}\\}$\n",
        "\n",
        "* Lados:\n",
        "  * $st$\n",
        "  * $tv_l \\space  \\forall  \\space \\text { literal l}$\n",
        "  * $v_{x_i}v_{\\overline x_i} \\space \\forall \\space i=1,...,n$\n",
        "  * $ a_{i,j} a_{2,j}  \\space \\space a_{2,j} a_{3,j} \\space \\space a_{3,j} a_{1,j} \\space \\space \\forall \\space j=1,...,m \\space$forman un triangulo\n",
        "  * $s e_{i,j}$ para $i = 1,2,3$ y $j = 1,2,...,m$\n",
        "  * Usando que es $3-SAT$, es decir, $D_j = l_{1,j} \\vee l_{2,j} \\vee l_{3,j}$ entonces tenemos $e_{i,j} v_{l_i,j}$ para $i=1,2,3$ y $j=1,2,...,m$. Ejemplo: si $D_j = (x \\vee \\overline x_2 \\vee x_4)$ entonces tengo $ \\overrightarrow{v_x e_{1,j}}$  $ \\overrightarrow{v_{\\overline x_2} e_{2,j}}$ $ \\overrightarrow{v_{x_4} e_{3,j}}$.\n",
        "\n",
        "\\\n",
        "Obsevemos que $G$ tiene un triángulo, entonces $\\chi(G) \\ge 3$, por lo que\n",
        "\n",
        "$$ \\chi(G)\\le 3 ⇔ \\chi(G) = 3 $$\n",
        "\n",
        "\\\n",
        "\n",
        "## (=>)\n",
        "\n",
        "Probemos primero:\n",
        "$$ \\chi(G)=3 ⇒ \\text {B es satisfacible}$$\n",
        "\n",
        "Como $\\chi(G) = 3$ entonces existe un coloreo propio de $G$ con 3 colores, llamemoslo $C$.\n",
        "\n",
        "Necesitamos definir un vector $(b_1,b_2,...,b_n) \\in \\{ 0,1\\}^n$ tal que $B(\\overrightarrow b) = 1$.\n",
        "\n",
        "Entonces, en base al coloreo $C$ definimos:\n",
        "\n",
        "$$ b_i = \\left\\{ \\begin{array}{lcc} 1 & si & C(v_{x_i}) = C(s) \\\\ \\\\ 0 & si & c.c.  \\end{array} \\right. $$\n",
        "\n",
        "Si queremos ver $B(\\overrightarrow b) = 1$, basta con ver que $D_j(\\overrightarrow b) = 1 \\space \\forall j $. Entonces tomemos un $j$ cualquiera. como para todo $j$ los $a_{1,j} a_{2,j} a_{3,j}$ forman un triángulo entonces los 3 colores deben aparecer ahí.\n",
        "\n",
        "En particular $∃ i : C(a_{i,j}) = C(t)$\n",
        "\n",
        "Como $e_{i,j} a_{i,j} \\in E ⇒ C(e_{i,j}) \\ne C(t)$\n",
        "\n",
        "Como $e_{i,j} s \\in E ⇒ C(e_{i,j}) \\ne C(s)$\n",
        "\n",
        "Como $ts \\in E ⇒ C(t) \\ne C(s)$\n",
        "\n",
        "Entonces $C(e_{i,j}) = \\text { tercer color (distinto de $s$ y $t$)} $.\n",
        "\n",
        "Ahora ya sabemos que color tienen los extremos de las garras. Entonces, vemos que $v_{l_{i,j}}e_{i,j} \\in E ⇒ C(v_{l_{i,j}}) \\ne C(e_{i,j}) = \\text { tercer color } ⇒ C(v_{l_{i,j}}) = C(t) \\space o \\space C(s)$.\n",
        "\n",
        "Pero $tv_{l_{i,j}} \\in E ⇒ C(v_{l_{i,j}}) \\ne C(t) $ entonces no queda otra que $C(v_{l_{i,j}}) = C(s) $ que es el candidato para cuando evalúe en $b_i = 1$.\n",
        "\n",
        "El $l_{i,j}$ es un literal por lo tanto es una variable o una negación.\n",
        "\n",
        "Veamos primero el caso de que es una variable:\n",
        "\n",
        "Entonces $∃ k : l_{i,j}= x_k$ entonces $v_{{l_{i,j}}} = v_{x_k}$, a su vez se da que $C(v_{l_{i,j}}) = C(s) ⇒ C(v_{x_k}) = C(s) ⇒ b_k=1$.\n",
        "\n",
        "Entonces $l_{i,j} = x_k ⇒ l_{i,j}(\\overrightarrow b) = x_k(\\overrightarrow b) = 1 ⇒ D_j(\\overrightarrow b) = 1.$\n",
        "\n",
        "Supongamos ahora que es negación de una variable $: ∃ k : l_{i,j} = \\overline x_k ⇒ l_{i,j} (\\overrightarrow b) = \\overline x_k(\\overrightarrow b) = 1 + b_k$\n",
        "\n",
        "Por $k : l_{i,j} = \\overline x_k$ podemos decir que $C(s) = C(v_{l_{i,j}}) = C(v_{\\overline x_k})$.\n",
        "\n",
        "Pero $v_{x_k}v_{\\overline x_k} \\in E   ⇒ C(v_{x_k}) \\ne C(v_{\\overline x_k})$\n",
        "\n",
        "Como son distintos y $C(v_{\\overline x_k}) = C(s)$ entonces $C(v_{x_k}) \\ne C(s) ⇒ b_k = 0.$ Entonces $ \\overline x_k(\\overrightarrow b) = 1 + 0 = 1 $.\n",
        "\n",
        "\\\n",
        "\n",
        "## (<=)\n",
        "\n",
        "$$ \\text {B es satisfacible} ⇒ \\chi(G)=3 $$\n",
        "\n",
        "Supongamos $B$ satisfacible $⇒ ∃ \\overrightarrow b \\in \\{ 0,1\\}^n : B(\\overrightarrow b) = 1$ y hay que definir un coloreo $C$.\n",
        "\n",
        "Definimos $C(s) = 1 $ y $C(t) = 2$. Hay que analizar si el coloreo es propio en cada caso: El lado $st$ no crea problemas ($NCP$).\n",
        "\n",
        "Para los $v_l$ definimos, $C(v_l) = l(\\overrightarrow b)$, en otras palabras:\n",
        "\n",
        "$$ C(v_{x_i}) = b_i \\in (0,1) $$\n",
        "$$ C(v_{\\overline x_i}) = 1 + b_i \\in (0,1) $$\n",
        "\n",
        "Veamos los casos:\n",
        "\n",
        "$$ \\underbrace{v_{x_i}}_{0 \\text{ o } 1} \\underbrace{v_{\\overline x_i}}_{1 \\text { o } 0}  ⇒ NCP$$\n",
        "\n",
        "$$\\underbrace{v_l}_{0 \\text{ o } 1} \\underbrace{t}_{2} ⇒ NCP $$\n",
        "\n",
        "Ahora como $B(\\overrightarrow b) = 1$ entonces $D_j(\\overrightarrow b) = 1$ $∀ \\space j ⇒ ∀ \\space j \\space ∃  \\space i = i_j : l_{i_j,j}(\\overrightarrow b) = 1$.\n",
        "\n",
        "Si hay más de unos , elijo un por ejemplo el primero.\n",
        "\n",
        "Coloreamos los $a_{i,j}$ de la siguiente forma:\n",
        "$$ C(a_{i_j,j}) = 2$$\n",
        "$$ C(a_{i,j}) = \\text{ 1 para uno y 0 para el otro}$$\n",
        "\n",
        "Como los colores de los $a_{i,j}$ son $0,1,2$ entonces el triángulo $NCP$ y colorelos los $e's$ de la siguiente forma:\n",
        "\n",
        "$$ C(e_{i,j}) = \\left\\{ \\begin{array}{lcc} 2 & si & i \\ne i_j \\\\ \\\\ 0 & si & i = i_j  \\end{array} \\right. $$\n",
        "\n",
        "Chequeamos los lados:\n",
        "\n",
        "$$ i \\ne i_j →  \\underbrace{a_{i,j}}_{0 \\text{ o } 1}  \\underbrace{e_{i,j}}_2 ⇒ NCP$$\n",
        "\n",
        "$$ i = i_j →  \\underbrace{a_{i,j}}_2  \\underbrace{e_{i,j}}_0 ⇒ NCP$$\n",
        "\n",
        "$$ \\underbrace{s}_{1}  \\underbrace{e_{i,j}}_{0 \\text { o } 2} ⇒ NCP$$\n",
        "\n",
        "Solo queda ver los $e_{i,j} v_{l_{i,j}}$:\n",
        "\n",
        "$$ i \\ne i_j →  \\underbrace{e_{i,j}}_{2}  \\underbrace{v_{l_{i,j}}}_{1 \\text { o } 0 } ⇒ NCP$$\n",
        "\n",
        "$$ i = i_j →  C(e_{i_j,j}) = 0 \\text { y } C(v_{l_{i_j,j}}) = l_{i_j,j}(\\overrightarrow b) = 1 ⇒  \\underbrace{e_{i,j}}_{0}  \\underbrace{v_{l_{i,j}}}_1 ⇒ NCP$$"
      ],
      "metadata": {
        "id": "EbST42CWXND0"
      }
    }
  ]
}